---
title: "PAC6"
author: "Maria Lucas Gascón"
date: "2024-01-17"
output: word_document
---

# Problema 1

Cargamos los datos del problema.

```{r}
# Seteamos el directorio de trabajo
setwd("D:/Antiguos estudios/MASTER2/Sem3/Diseño/PAC6/PAC6")

# Importamos los datos
data <- read.csv("dades_problema1_pec6.csv", dec = ",", header = TRUE, sep = ";")

# Marcamos los factores
data$espectrometro <- as.factor(data$espectrometro)
data$suelo <- as.factor(data$suelo)
data$dia <- factor(data$dia, levels = c(1, 2, 3), labels = c("dia1", "dia2", "dia3"))
```

## 1.1 Análisis descriptivo de los datos

```{r}
# Primero examinamos la variable ratio
summary(data)

# Box plot de ratio por espectrometro
boxplot(ratio ~ espectrometro, data = data, col = c("blue4", "aquamarine2", "cadetblue1"), main = "Boxplot de Ratio por Espectrómetro")

# Box plot de ratio por suelo
boxplot(ratio ~ suelo, data = data, col = c("darkslateblue", "darkviolet"), main = "Boxplot de Ratio por Suelo")

# Box plot de ratio por dia
boxplot(ratio ~ dia, data = data, col = c("darkgreen", "chartreuse3", "darkolivegreen2"), main = "Boxplot de Ratio por Dia")
```

```{r, fig.width=15, fig.height=10}
# Create an interaction factor of espectrometro and suelo
espectrometro_suelo <- interaction(data$espectrometro, data$suelo)

# Box plot of ratio by espectrometro and suelo
boxplot(data$ratio ~ espectrometro_suelo, col = c("blue4", "aquamarine2", "cadetblue1", "darkslateblue", "darkviolet", "pink3"), 
        main = "Boxplot de Ratio por Espectrómetro y Suelo")
```

En el análisis del boxplot correspondiente al "Ratio por Espectrómetro", se observa una ligera disparidad en las mediciones entre los espectrómetros. Esta discrepancia se evidencia mediante la diferencia en la altura de las cajas y la variación en la media de las mediciones, destacada por una línea negra en cada caja.

En cuanto al boxplot relativo al "Ratio por Suelo", se destaca que el suelo rural presenta, en general, un ratio de 14N a 15N superior al observado en el suelo urbano. Esta diferencia se refleja tanto en la altura como en el ancho de las cajas, indicando que el suelo rural exhibe un ratio más elevado en comparación con el suelo urbano.

Adicionalmente, se observa una notable consistencia en las mediciones diarias, ya que muestran una variación mínima.

Al combinar los datos de espectrómetro y suelo en un único gráfico, se puede evaluar la interacción entre ambos factores. Se aprecia que, para el suelo urbano, las mediciones de los espectrómetros presentan una mayor disparidad en comparación con el suelo rural, donde las mediciones son más uniformes. Específicamente, se destaca que el espectrómetro 2 en el suelo urbano proporciona mediciones notablemente más bajas.

## 1.2 Modelo lineal

En este problema, se busca modelar la proporción de 14N a 15N en dos tipos de suelos (urbano, rural) utilizando tres espectrómetros distintos. Se realizaron mediciones en 18 muestras de cada tipo de suelo. Cada muestra se asignó a uno de los tres espectrómetros al azar, y para cada combinación de suelo y espectrómetro, se eligieron 3 días al azar para realizar las mediciones. El objetivo es analizar la influencia de los factores suelo, espectrómetro y día, así como sus interacciones.

El modelo lineal puede expresarse de la siguiente manera:

$Y_{ijk} = \mu + \alpha_{i} + \beta_{j} + (\alpha\beta)_{ij} + C_{k(ij)} + \epsilon_{ijk}$

+ $Y_{ijk}$ es la medida de la proporción de 14N a 15N para la k-ésima observación en el suelo i, espectrómetro j y día k.
+ $\mu$ es la media global.
+ $\alpha_{i}$ es el efecto del i-ésimo nivel del factor suelo. La suma de todos los efectos del factor suelo debe ser cero: $\sum_{i = 1}^{2} \alpha_{i}=0$
+ $\beta_{j}$ es el efecto del j-ésimo nivel del factor espectrómetro. La suma de todos los efectos del factor espectrómetro debe ser cero: $\sum_{j = 1}^{3} \beta_{i}=0$
+ $(\alpha\beta)_{ij}$ es la interacción entre el suelo i y el espectrómetro j. La suma de las interacciones debe ser cero: $\sum\alpha\beta_{ij}=0$
+ $C_{k(ij)}$ es el efecto del k-ésimo nivel del factor día anidado en la combinación suelo i y espectrómetro j. Como es un efecto aleatorio, no hay restricciones específicas, pero se asume que sigue una distribución normal con media cero: $C_{k(ij)} \sim N(0, \sigma^2_{C})$
+ $\epsilon_{ijk}$ es el error aleatorio asociado con la k-ésima observación en la combinación suelo i, espectrómetro j y día k. Se asume que sigue una distribución normal con media cero: $\epsilon_{ijk} \sim N(0, \sigma^2_{\epsilon})$

## 1.3 Hipótesis de interés

Para el factor suelo:

+ $H_{0} : \alpha_{1} = \alpha_{2} = 0$. No hay diferencia significativa en la proporción de 14N a 15N entre los suelos urbanos y rurales.
+ $H_{1}:$ Almenos un $\alpha_{i} \ne 0$. Hay al menos una diferencia significativa en la proporción de 14N a 15N entre los suelos urbanos y rurales.

Para el factor espectrómetro:

+ $H_{0}: \beta_{1} = \beta_{2} = \beta_{3} = 0$. No hay diferencia significativa en la proporción de 14N a 15N entre los espectrómetros.
+ $H_{1}:$ Almenos un $\beta_{j} \ne 0$. Hay al menos una diferencia significativa en la proporción de 14N a 15N entre los tres espectrómetros distintos.

Para la interacción suelo-espectrómetro:

+ $H_{0}: (\alpha\beta)_{ij} = 0$ para todos los $i, j$. No hay interacción significativa entre el tipo de suelo y el espectrómetro.
+ $H_{1}:$ Existe al menos una $(\alpha\beta)_{ij} \ne 0$. Hay al menos una interacción significativa entre el tipo de suelo y el espectrómetro.

Para el efecto aleatorio del día:

+ $H_{0}: \sigma^2_{C(AB)} = 0$. No hay variabilidad significativa asociada con los días anidados en la combinación de suelo y espectrómetro.
+ $H_{1}: \sigma^2_{C(AB)} > 0$. Existe variabilidad significativa asociada con los días anidados en la combinación de suelo y espectrómetro.

Para el error aleatorio:

+ $H_{0}: \sigma^2_{\epsilon} = 0$. No hay variabilidad significativa no explicada por los factores considerados en el modelo.
+ $H_{1}: \sigma^2_{\epsilon} > 0$. Existe variabilidad significativa no explicada por los factores considerados en el modelo.

## 1.4 Estudiar las hipótesis

```{r}
# Definimos el modelo
library(lme4)
library(car)

modelo <- lmer(ratio ~ suelo + espectrometro + suelo:espectrometro + (1 | dia:suelo:espectrometro), data = data)

summary(modelo)

# Intervalos de confianza
library(broom)
confint(modelo)
```

En la síntesis del modelo, no se evidencian los factores que resultan significativos. No obstante, es posible calcular los valores de confianza mediante el empleo de un valor crítico de la distribución t de Student. En esta distribución, un nivel de confianza del 0.05 implicaría un valor crítico de 1.96.

El intervalo de confianza se formula como el estimado del coeficiente más o menos 1.96 veces el error estándar del coeficiente. Para mayor conveniencia, este cálculo se realiza de forma automática mediante el paquete "broom".

Al examinar los intervalos de confianza, se constata que todos los factores son estadísticamente significativos, a excepción del espectrómetro 2, ya que su intervalo de confianza incluye el valor 0. Por otro lado, el intercepto, el suelo urbano, el espectrómetro 3 y las interacciones suelo urbano:espectrómetro 2 y suelo urbano:espectrómetro 3, exhiben diferencias significativas en comparación con la referencia establecida, que corresponde al suelo rural y el espectrómetro 1.

```{r}
# Testamos las hipótesis
anova_modelo <- Anova(modelo, type = "III", test = "Chisq")
print(anova_modelo)
```

La especificación de la ANOVA de "tipo III" implica la atribución de variabilidad a cada término, teniendo en cuenta todos los demás términos, incluidas las interacciones que involucran dicho término. Esta aproximación resulta útil cuando se presentan interacciones y se busca evaluar la contribución de cada variable a la variabilidad explicada, considerando las otras variables y sus interacciones.

Cabe destacar que, dado que no se han verificado las suposiciones de normalidad y homocedasticidad, se prefiere utilizar la prueba de Chi-cuadrado en lugar de la prueba F.

En cuanto a los resultados, se observa que tanto el suelo como la interacción suelo:espectrofotómetro son significativas (valor de p < 0.05), mientras que el espectrofotómetro por sí mismo no lo es (valor de p > 0.05). A continuación, se detalla la interpretación de estos hallazgos:

+ Suelo significativo: Se constatan diferencias estadísticamente significativas en la proporción de 14N a 15N entre los suelos urbanos y rurales (valor de p < 0.05, rechazo de H0), después de considerar los demás efectos en el modelo. En resumen, existe evidencia estadística que respalda la afirmación de que el tipo de suelo tiene un impacto significativo en la proporción de nitrógeno.

+ Espectrómetro no significativo: No se dispone de suficiente evidencia estadística para sostener que existen diferencias en la proporción de 14N a 15N entre los distintos espectrofotómetros (valor de p > 0.05, aceptación de H0), después de tomar en cuenta los otros efectos. En resumen, las variaciones observadas en la proporción de nitrógeno no pueden atribuirse de manera significativa a las diferencias entre los espectrofotómetros utilizados. Es posible que la no significancia se deba a que el espectrofotómetro 3 no difiere, a pesar de que el 2 sí lo hace según el intervalo de confianza.

+ Interacción suelo-espectrómetro significativa: Se evidencia que la influencia del espectrofotómetro en la proporción de nitrógeno depende del tipo de suelo (valor de p < 0.05, rechazo de H0). En otras palabras, la diferencia en la proporción de 14N a 15N entre los espectrofotómetros puede variar según si el suelo es urbano o rural. Esta interacción indica que el efecto del espectrofotómetro no es constante en todos los suelos y viceversa.

En resumen, los resultados sugieren que el tipo de suelo y la interacción entre el tipo de suelo y el espectrofotómetro son factores significativos en la variabilidad de la proporción de 14N a 15N, mientras que el espectrofotómetro por sí mismo no tiene un efecto significativo en esta proporción, aunque este patrón parece no aplicar al espectrofotómetro 2.

## 1.5 Comparaciones múltiples

Dado que el factor suelo consta únicamente de dos niveles, carece de fundamento llevar a cabo una comparación múltiple. A pesar de que el espectrómetro no muestra significancia de manera general, hemos observado que el espectrómetro 2 presenta un significado estadístico; procederemos a verificar estos resultados. Por último, examinaremos también la interacción suelo:espectrómetro.

#### Para la interacción:

```{r}
# install.packages("emmeans")
library(emmeans)
library(knitr)

# Realizamos las comparaciones múltiples
emmeans_result <- emmeans(modelo, pairwise ~ suelo:espectrometro)

# Ajustamos p-valores usando la corrección de Bonferroni
adjusted_emmeans <- summary(emmeans_result, infer = c(TRUE, TRUE), adjust = "bonferroni")

# Imprimimos los valores ajustados
print(adjusted_emmeans)
```

Como podemos ver, las siguientes combinaciones resultan significativas:

```{r}
# Extraemos los contrastes y p-valores
contrast_df <- as.data.frame(adjusted_emmeans$contrasts)

# Filtramos por p-valores < 0.05
significant_contrasts <- contrast_df[contrast_df$p.value < 0.05, c("contrast", "p.value")]


# Formateamos la tabla para imprimir
formatted_table <- data.frame(
  Contrast = significant_contrasts$contrast,
  P_Value = sprintf("%.4f", significant_contrasts$p.value)
)

# Imprimimos la tabla
library(knitr)
kable(formatted_table, col.names = c("Contraste", "P-Valor"), format = "pandoc")
```

Eso significa que:

+ Hay evidencia significativa para afirmar que la proporción de nitrógeno en el suelo rural es diferente cuando se utiliza el espectrómetro_1 en comparación con el suelo urbano cuando se utiliza el espectrómetro_2.
+ Hay evidencia significativa para afirmar que la proporción de nitrógeno en el suelo rural es diferente cuando se utiliza el espectrómetro_2 en comparación con el suelo urbano cuando también se utiliza el espectrómetro_2.
+ Hay evidencia significativa para afirmar que la proporción de nitrógeno en el suelo urbano es diferente cuando se utiliza el espectrómetro_2 en comparación con el suelo rural cuando se utiliza el espectrómetro_3.
+ Hay evidencia significativa para afirmar que la proporción de nitrógeno en el suelo urbano es diferente cuando se utiliza el espectrómetro_2 en comparación con el mismo suelo urbano cuando se utiliza el espectrómetro_3.

Estos valores de p bajos indican que, tras ajustar para múltiples comparaciones, las diferencias observadas en estas combinaciones específicas son estadísticamente significativas. Para las demás combinaciones, no se detectan diferencias significativas.

Es relevante subrayar la importancia de realizar correcciones para mitigar el error de tipo 1, especialmente dado el gran número de comparaciones efectuadas. En este caso, se ha implementado la corrección de Bonferroni.

#### Para el espectrómetro:

```{r}
# Instalar el paquete emmeans si aún no lo has hecho
# install.packages("emmeans")

# Cargar el paquete
library(emmeans)

# Calcular las medias marginales ajustadas (LSMeans)
lsmeans_modelo <- emmeans(modelo, ~espectrometro)

# Comparaciones múltiples entre niveles de espectrómetros
comparaciones <- pairs(lsmeans_modelo)

# Ver los resultados
summary(comparaciones)

```

Se ratifica la existencia de una disparidad significativa entre el espectrómetro 2 y el espectrómetro 1, dado que se obtiene un valor de 0.03, lo cual conduce al rechazo de la hipótesis nula (H0) que sostiene que no existen diferencias entre ambos. Por otro lado, se constata la ausencia de discrepancias entre el espectrómetro 1 y el espectrómetro 3, así como entre el espectrómetro 2 y el espectrómetro 3 (valor de p > 0.05). Este resultado ya se reflejaba en el resumen del modelo, aunque la comparación entre el espectrómetro 2 y el espectrómetro 3 no estaba detallada.

# Problema 2

Cargamos los datos del problema.

```{r}
# Seteamos el directorio de trabajo
setwd("D:/Antiguos estudios/MASTER2/Sem3/Diseño/PAC6/PAC6")

# Importamos los datos
data <- read.csv("dades_problema2_pec6.csv", dec = ",", header = TRUE, sep = ";")

# Marcamos los factores
data$dieta <- as.factor(data$dieta)
```

## 2.1 Análisis descriptivo de los datos

```{r}
# Realiza un resumen descriptivo
summary(data)

# Gráfico relación consumo-incremento
color_dieta = c("tomato1", "olivedrab3", "turquoise", "slateblue2")

# Boxplot incremento por dieta
boxplot(incremento ~ dieta, data = data, col = color_dieta)

# Boxplot consumo por dieta
boxplot(consumo ~ dieta, data = data, col = color_dieta)

library(ggplot2)

# Gráfico de dispersión Incremento vs Consumo sin dieta
ggplot(data, aes(x = consumo, y = incremento)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Añade la línea de tendencia general
  labs(title = "Relación entre Incremento y Consumo",
       x = "Consumo",
       y = "Incremento") +
  theme_minimal()

# Gráfico de dispersión Incremento vs Consumo por dieta
ggplot(data, aes(x = consumo, y = incremento, color = factor(dieta))) +
  scale_color_manual(values = color_dieta) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Añade la línea de tendencia + 
  labs(title = "Relación entre Incremento y Consumo por Dieta",
       x = "Consumo",
       y = "Incremento") +
  theme_minimal()
```

Se evidencia una distribución equilibrada con 5 animales por cada tipo de dieta, lo que configura un diseño balanceado.

El análisis del primer boxplot, que representa la relación entre el incremento de peso y la dieta, sugiere variaciones significativas entre los grupos. Esto se infiere al observar diferencias en las alturas de las cajas y la línea central, que representa la media de cada grupo. Además, las distintas alturas y longitudes de las líneas de dispersión indican variabilidades divergentes entre los grupos.

En contraste, al examinar el segundo boxplot que relaciona el consumo de calorías con la dieta, se puede inferir si existen disparidades en el consumo calórico entre los grupos. Efectivamente, se observan diferencias notables entre los grupos.

Por otro lado, el gráfico que ilustra la relación entre el aumento de peso y el consumo calórico revela una correlación positiva general. A mayor consumo de calorías, se evidencia un mayor incremento de peso, y viceversa.

Al analizar esta relación de manera específica para cada dieta, se mantiene la correlación positiva, pero se aprecian pendientes distintas para cada tipo de dieta. Destaca que la dieta 4 exhibe la correlación positiva más pronunciada.

En conjunto, estos hallazgos contribuyen a una comprensión más profunda de las relaciones entre las variables, lo que facilita el ajuste preciso de los modelos de regresión.

## 2.2 Modelo Lineal

### Ajustando según el consumo calórico

El modelo lineal, teniendo en cuenta el consumo calórico, puede especificarse como:

$y_{ij} = \mu + \alpha_{i} + \beta X_{ij} + \epsilon_{ij}$

Donde:

+ $y_{ij}$ es el aumento de peso del animal $j$ bajo la dieta $i$.
+ $\mu$ es el intercepto común para todas las dietas.
+ $\alpha_{i}$ es el intercepto específico para la dieta $i$.
+ $\beta$ es la pendiente de regresión, que representa el efecto del consumo calórico en el aumento de peso.
+ $Xij$ es el consumo calórico del animal $j$ bajo la dieta $i$.
+ $\epsilon_{ij}$ son errores experimentales aleatorios con distribución normal, media 0 y varianza $\sigma^2$. ($\epsilon_{ij} \sim N(0, \sigma^2)$).

Suposiciones adicionales:

+ $\sum_{i}^{a} \alpha_{i}=0$
+ El coeficiente de regresión $\beta$ es el mismo para todos los grupos de tratamiento (dietas).
+ Las dietas no influyen sobre el consumo calórico (covariante $X$)

El modelo covariante propone utilizar una línea de regresión para cada tratamiento. Esta línea representa cómo la variable de interés cambia en relación con la covariable. Todas las líneas son similares en términos de la dirección de cambio, es decir, comparten la misma "pendiente" ($β$). Esto significa que todos los tratamientos responden de manera similar a la covariable.

Sin embargo, hay diferencias entre los tratamientos, y estas diferencias se reflejan en los términos independientes o "ordenadas al origen" ($\mu + \alpha_{i}$). Cada tratamiento tiene su propia ordenada al origen ($\alpha_{i}$), que se suma a una ordenada al origen común ($\mu$). Esto significa que aunque las líneas son paralelas, pueden tener alturas diferentes en el eje vertical, indicando que cada tratamiento puede tener un nivel inicial diferente en la variable de interés.

En resumen, el modelo utiliza líneas de regresión paralelas para representar cómo los diferentes tratamientos responden a la covariable, con la flexibilidad de tener diferentes niveles iniciales debido a los términos $\alpha_{i}$.

### Sin ajustar por consumo calórico

El modelo lineal, sin tener en cuenta el consumo calórico, puede especificarse como:

$y_{ij} = \mu + \alpha_{i} + \epsilon_{ij}$

Donde:

+ $y_{ij}$ es el aumento de peso del animal $j$ bajo la dieta $i$.
+ $\mu$ es el efecto medio global.
+ $\alpha_{i}$ es el efecto adicional de la dieta $i$ en comparación con el promedio global.
+ $\epsilon_{ij}$ son errores experimentales aleatorios con distribución normal, media 0 y varianza $\sigma^2$. ($\epsilon_{ij} \sim N(0, \sigma^2)$).

En este caso, el modelo lineal es mucho más simple porque no se tiene en cuenta la covariable consumo. Es por ello que este modelo simple describe cómo las observaciones ($y_{ij}$) se componen del nivel medio común ($\mu$), la contribución única de cada tratamiento ($\alpha_{i}$), y la variabilidad no explicada ($\epsilon_{ij}$).

## 2.3 Efecto de la dieta

### Ajustando el consumo

```{r}
# Ajustar el modelo lineal
modelo_con <- lm(incremento ~ dieta + consumo, data = data)

summary(modelo_con)
```

En el caso de variables dummy que representan categorías (como las dietas), el término constante (o intercepto) es la estimación del valor medio de la variable de respuesta para la categoría de referencia. En este caso, la dieta 1 es la categoría de referencia. Entonces, el término constante representará la estimación del aumento de peso medio para la dieta 1. Las otras variables dummy (dieta 2, dieta 3 y dieta 4) indicarán cómo difieren las otras dietas en comparación con la dieta 1. En resumen, se puede considerar que la dieta 1 es equivalente al intercepto en este contexto específico.

Una vez explicado esto, podemos ver en el resumen del modelo que la estimación para la dieta 1 (intercepto) es de 15.74, y para la dieta 2 es de -14.94. Esto quiere decir que la dieta 1 hace que el peso incremente más que con la dieta 2. No debemos confundir que el estimado de la dieta 2 sea negativo con que disminuya el peso, si no que aumenta pero en menor medida que con la dieta 1, que es con la que se está comparando. Esto concuerda con la exploración inicial de los datos, en la que la dieta 1 mostraba mayor incremento de peso que la dieta 2.

### Sin ajustar el consumo

```{r}
# Ajustar el modelo lineal
modelo_sin <- lm(incremento ~ dieta, data = data)

# Resumen del modelo
summary(modelo_sin)
```

En este caso, el estimado para la dieta 1 es de 63, mientras que para la dieta 2 es de -15.8. Como mencionamos previamente, esto indica que la dieta 1 está asociada con un mayor aumento de peso en comparación con la dieta 2.

Al comparar el estimado de la dieta 1 ajustando el modelo con y sin la covariable, notamos una diferencia sustancial en la estimación (15.74 vs 63). Esta disparidad probablemente se debe a la omisión del efecto del consumo calórico en el modelo sin covariable.

Como hemos observado en la exploración de datos, existe una relación positiva entre la covariable (consumo) y la variable de respuesta. Al no incluir esta covariable en el modelo, parte de la variabilidad debida al consumo se atribuye erróneamente a la variable dieta. Esto se refleja en un estimado más alto para la dieta 1, que sirve como referencia.

Al incorporar el consumo como una covariable en el modelo, estamos intentando aislar el efecto específico de la dieta en el aumento de peso, controlando o ajustando por las diferencias en el consumo entre las dietas. Este enfoque proporciona una estimación más precisa del efecto de la dieta, eliminando el posible sesgo en la relación entre la covariable y la variable de respuesta.

En resumen, al incluir el consumo como covariable, se mejora la capacidad del modelo para discernir entre los efectos de la dieta y el consumo en el aumento de peso, lo que resulta en estimaciones más ajustadas y potencialmente más precisas.

## 2.4 Diagnosis de suposiciones

#### Independencia de los residuos

```{r}
# Gráfico de residuos vs. orden de observaciones
plot(resid(modelo_con) ~ seq_along(resid(modelo_con)))

library(lmtest)
# Prueba de Durbin-Watson para autocorrelación de los residuos
dwtest(modelo_con)
```

En la representación gráfica, se observa la ausencia de patrones evidentes en los residuos. Este hallazgo se corrobora mediante la aplicación del test de Durbin-Watson, el cual indica la inexistencia de correlaciones significativas entre los residuos (valor de p > 0.05, aceptamos H0).

#### Homocedasticidad

```{r}
plot(modelo_con, which=1)

# Prueba de Breusch-Pagan para homocedasticidad
library(lmtest)
bptest(modelo_con)
```

La dispersión de los residuos es constante a medida que cambian los valores ajustados. Vemos una dispersión uniforme de puntos alrededor de cero, indicando homocedasticidad.

Por otro lado, la prueba de Breusch-Pagan testa la H0 de homocedasticidad. Como obtenemos un pvalor alto (mayor que 0.05) sugiere que no hay suficiente evidencia para rechazar la hipótesis nula, indicando homocedasticidad.

#### Normalidad

```{r}
plot(modelo_con, which=2)

shapiro.test(modelo_con$residuals)
```

Tanto a partir del QQ-Plot (puntos alrededor de la diagonal), como el test de Shapiro-Wilks (p-valor > 0,05), concluimos que los residuos son normales.

#### Interacción tratamiento-consumo

```{r}
modelo_interaccion <- lm(incremento ~ consumo * dieta, data = data)
Anova(modelo_interaccion)
```

Se advierte que la interacción entre el consumo y la dieta no alcanza significancia estadística.

La observación de estos parámetros confirma que el modelo satisface las suposiciones necesarias, permitiendo así la continuación del análisis sin inconvenientes.

## 2.5 Diferencias entre dietas

Para determinar entre qué dietas hay diferencias significativas, se deben realizar pruebas de comparaciones múltiples.

```{r}
# Instalar y cargar el paquete multcomp
# install.packages("multcomp")
library(multcomp)

# Realizar comparaciones múltiples con el método de Tukey
comp <- glht(modelo_con, linfct = mcp(dieta = "Tukey"))

# Resumen de las comparaciones con ajuste de pvalores
resumen_comp <- summary(comp)
pvalores_ajustados <- p.adjust(resumen_comp$test$pvalues, method = "bonferroni")
resumen_comp$test$pvalues_ajustados <- pvalores_ajustados

# Mostrar el resumen con pvalores ajustados
print(resumen_comp)
```

Se efectuaron comparaciones múltiples mediante el método de Tukey, y tras ajustar los valores de p mediante el procedimiento de Bonferroni, se constata la presencia de diferencias estadísticamente significativas entre las dietas 4 y 1, entre las dietas 3 y 2, y, finalmente, entre las dietas 4 y 3.

# Problema 3

Cargamos los datos del problema.

```{r}
# Seteamos el directorio de trabajo
setwd("D:/Antiguos estudios/MASTER2/Sem3/Diseño/PAC6/PAC6")

# Importamos los datos
data <- read.csv("dades_problema3_pec6.csv", dec = ".", header = TRUE, sep = ",")

# Marcamos los factores
data$tratamiento <- as.factor(data$tratamiento)
data$paciente <- as.factor(data$paciente)
```

## 3.1 Análisis descriptivo

```{r}
# Realiza un resumen descriptivo
summary(data)

color_tratamiento = c("tomato1", "olivedrab3")

# Boxplot depresión por dieta
boxplot(depresion ~ tratamiento, data = data, col = color_tratamiento)

# Boxplot depresión por tiempo
boxplot(depresion ~ tiempo, data = data)

library(ggplot2)

# Gráfico de dispersión depresión vs tiempo
ggplot(data, aes(x = tiempo, y = depresion)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Añade la línea de tendencia general
  labs(title = "Relación entre Depresión y Tiempo",
       x = "Tiempo",
       y = "Depresión") +
  theme_minimal()

# Gráfico de dispersión depresión vs tiempo con tratamiento
ggplot(data, aes(x = tiempo, y = depresion, color = factor(tratamiento))) +
  scale_color_manual(values = color_tratamiento) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Añade la línea de tendencia + 
  labs(title = "Relación entre Depresión y Tiempo",
       x = "Tiempo",
       y = "Depresión") +
  theme_minimal()
```

Con base en la observación del diagrama de cajas, se sugiere que el tratamiento 1 exhibe una disminución en la prevalencia de la depresión en comparación con el tratamiento 0.

En relación al segundo diagrama de cajas, se aprecia una aparente reducción en la depresión posparto conforme transcurre el tiempo, manifestada por una tendencia descendente en las medianas representadas por las cajas.

Este hallazgo se corrobora al analizar el gráfico de dispersión, donde la línea de tendencia general, identificada en azul, presenta una disminución gradual a lo largo del período de tiempo estudiado.

Al segmentar los resultados según el tipo de tratamiento, se sugiere que el tratamiento exhibe una pendiente descendente ligeramente más pronunciada que la del tratamiento 0.

```{r, fig.width=10, fig.height=15}
ggplot(data, aes(x = tiempo, y = depresion)) + 
  geom_smooth(method = "lm", level = 0.95) +
  geom_point() + 
  facet_wrap(~ paciente, nrow = 10, ncol = 5) +
  theme(
  )
```

Finalmente, al examinar la evolución temporal de la depresión por paciente, se evidencia que algunos individuos experimentan una reducción marcada, mientras que en otros casos la evolución es mínima, ilustrada por líneas de tendencia notablemente planas (por ejemplo, paciente 2 vs. paciente 10). Es relevante destacar que en ningún caso se observa una tendencia ascendente, indicativa de un aumento en la prevalencia de la depresión con el paso del tiempo.

## 3.2 Modelo lineal

$Y_{ij} = \beta_{0} + \beta_{1}*tratamiento_{i} +  \beta_{2}*tiempo_{ij} + \beta_{3}*(tratamiento_{i}$ x $tiempo_{ij}) + u_{i0} + u_{il}*tiempo_{ij} + \epsilon_{ij}$

Donde:

+ $Y_{ij}$ es la medida de depresión para la i-ésima paciente en la j-ésima visita.
+ $tratamiento_{i}$ es la variable indicadora para el tratamiento (1 si es activo, 0 si es placebo). Es decir, la "i" en $tratamiento_{i}$ no indica el indice del tratamiento si no el número de paciente, el propio "$tratamiento_{i}$" es indicador de tratamiento.
+ $tiempo_{ij}$ es el tiempo de la j-ésima visita para la i-ésima paciente.
+ $\beta_{0}$ es la intercepción fija del modelo.
+ $\beta_{1}$ es el efecto fijo del tratamiento.
+ $\beta_{2}$ es el efecto fijo del tiempo.
+ $\beta_{3}$ representa la interacción entre el tratamiento y el tiempo.
+ $u_{i0}$ es el término aleatorio que modela las diferencias individuales en las intercepciones.
+ $u_{il}$ es el término aleatorio que modela las diferencias individuales en las pendientes respecto al tiempo.
+ $\epsilon_{ij}$ es el término de error.

Cabe destacar que i=50 porque hay 50 pacientes y j=7 porque se mide la depresión en 7 visitas.

Este modelo puede expresarse en notación matricial de la siguiente manera:

$Y = X\beta + Zu + \epsilon$

Dimensiones:

+ N=50×7=350N=50×7=350: Número total de observaciones.
+ k: Número de tratamientos.
+ p: Número de efectos fijos no relacionados con el tratamiento.
+ q: Número de efectos aleatorios.

Ahora, definimos las matrices y vectores según estas dimensiones:

+ $Y$: Vector de todas las medidas de depresión, de dimensión 350×1350×1.
+ $X$: Matriz de regresión de efectos fijos, de dimensión 350×(k+p)350×(k+p).
+ $β$: Vector de coeficientes de efectos fijos, de dimensión (k+p)×1(k+p)×1.
+ $Z$: Matriz de regresión de efectos aleatorios, de dimensión 350×q350×q.
+ $u$: Vector de efectos aleatorios, de dimensión q×1q×1.
+ $\epsilon$: Vector de errores, de dimensión 350×1350×1.

Particionado para cada elemento, quedaría como:

$Y = $

$$\begin{bmatrix}
Y_{1} \\
Y_{2} \\
. \\
. \\
. \\
Y_{350}\\
\end{bmatrix}$$

## 3.3 Implementación del modelo

### Intercepciones aleatorias

Con el propósito de ajustar el presente modelo, se ha definido que la variable dependiente es la depresión, mientras que las variables independientes son el tratamiento y el tiempo. La inclusión del término "tratamiento * tiempo" se justifica por la posibilidad de que existan efectos diferenciados del tiempo según el tipo de tratamiento, dando cabida a la interacción entre ambas variables. Además, la especificación "(1|paciente)" indica que se está modelando un intercepto aleatorio para cada paciente, con el fin de tener en consideración la variabilidad existente entre los distintos pacientes en el análisis.

```{r}
# install.packages("lme4", dependencies=TRUE)
# install.packages("Matrix", dependencies=TRUE)
library(lme4)

# Define el modelo con intercepciones aleatorias
modelo1 <- lmer(depresion ~ tratamiento * tiempo + (1|paciente), data = data)

# Muestra un resumen del modelo
summary(modelo1)
```

### Intercepciones y pendientes aleatorias

Para llevar a cabo la especificación de este modelo, se ha designado la variable de respuesta como la medida de depresión, considerando tanto el tratamiento como el tiempo como variables independientes. La inclusión del término "tratamiento * tiempo" se justifica al incorporar la interacción entre tratamiento y tiempo, considerando la posibilidad de que existan efectos temporales diferenciados dependiendo del tipo de tratamiento.

Adicionalmente, la especificación "(tiempo | paciente)" establece la modelización de una intercepción aleatoria y una pendiente aleatoria para cada paciente. Este término implica que cada individuo podría presentar una intercepción (efecto inicial) y una pendiente (efecto en el tiempo) propias con respecto a la variable de respuesta.

Cabe señalar que se ha optado por no incluir variaciones aleatorias en la variable tratamiento (tratamiento | paciente). Esta decisión se fundamenta en la consideración de que permitiría que la relación entre la depresión y el tratamiento varíe aleatoriamente entre pacientes. En el contexto de la problemática abordada, donde se está evaluando un fármaco, no resulta deseable que los pacientes reaccionen de manera diversa al tratamiento. Se parte del supuesto de que el fármaco, al ser considerado para su comercialización, debería inducir un efecto uniforme en todos los individuos, aunque se reconoce que la respuesta de cada paciente puede diferir a lo largo del tiempo.

```{r}
library(lme4)

# Define el modelo con intercepciones y pendientes aleatorias
modelo2 <- lmer(depresion ~ tratamiento * tiempo + (tiempo | paciente), data = data)

# Muestra un resumen del modelo
summary(modelo2)
```

### Comparación de modelos

```{r}
# Comparación de modelos usando likelihood ratio test
anova(modelo1, modelo2)
```

Según la prueba de razón de verosimilitud, se observa una diferencia significativa entre los dos modelos evaluados (valor de p < 0.05). En virtud de este hallazgo, se concluye que el modelo más complejo es preferible, ya que demuestra una mejor capacidad para explicar la variabilidad inherente a la variable de respuesta.

Asimismo, esta prueba proporciona los valores del Criterio de Información de Akaike (AIC) y del Criterio de Información Bayesiano (BIC). Estas medidas evalúan la calidad del ajuste de un modelo, considerando simultáneamente su complejidad. De manera general, se consideran más deseables aquellos modelos que presentan valores más bajos de AIC y BIC.

El AIC penaliza la complejidad del modelo de manera menos severa que el BIC. Un valor más bajo de AIC indica un mejor equilibrio entre ajuste y parsimonia.

En contraste, el BIC penaliza la complejidad del modelo de forma más estricta que el AIC. Una disminución en el valor de BIC sugiere un mejor balance entre el ajuste del modelo y su complejidad.

Con base en esta información, se concluye que el modelo que incorpora intercepciones y pendientes aleatorias es preferible al modelo que únicamente considera intercepciones aleatorias.

## 3.4 Factores significativos

```{r}
summary(modelo1)
```

Una vez más, debemos calcular los intervalos de confianza para determinar la significatividad de los factores.

```{r}
# install.packages("broom")
library(broom)

# Intervalos de confianza
confint(modelo1)
```

Los factores que adquieren significancia se identifican a través de la observación de intervalos de confianza que no incorporan el valor 0.

Se constata que únicamente el intervalo de confianza correspondiente al tratamiento 1 incluye el valor 0. Esto indica que los restantes factores (tiempo e interacción tiempo:tratamiento) son estadísticamente significativos, mientras que el tratamiento no lo es.

Este hallazgo plantea perspectivas poco alentadoras para el estudio clínico, ya que sugiere que el tratamiento no ejerce un efecto discernible sobre la depresión. En cambio, parece que la disminución de la depresión ocurre de forma natural a lo largo del tiempo en las pacientes, independientemente de la administración del fármaco.

No obstante, la presencia de una interacción significativa sugiere que la relación entre el tratamiento y la respuesta de depresión experimenta cambios significativos a lo largo del tiempo. En otras palabras, el impacto del tratamiento podría variar en diferentes momentos del estudio. Esta dinámica podría ser objeto de un examen más detenido: es posible que el tratamiento no surta un efecto inmediato, sino que requiera un período de tiempo para manifestarse. O bien, podría indicar que el tratamiento ejerce un efecto destacado en ciertos momentos específicos (por ejemplo, períodos de tiempo particulares después de la administración), pero no en otros. Alternativamente, el tratamiento podría influir de manera dispar en la respuesta de depresión en distintos momentos del estudio, y estas variaciones a lo largo del tiempo podrían amalgamarse de tal manera que el efecto general del tratamiento no alcance significancia.

Para obtener mayor claridad sobre estos efectos, se podrían llevar a cabo análisis exploratorios y post hoc adicionales.

## 3.5 Modelo estimado en las pacientes 1 y 26

```{r}
coef(modelo1)$paciente["1",]
coef(modelo1)$paciente["26",]
```


Tal y como hemos explicado antes:

$depresion = \beta_{0} + \beta_{tratamiento}*tratamiento + \beta_{tiempo}*tiempo + \beta_{tratamiento:tiempo}*tratamiento:tiempo + b_{paciente} + \epsilon$

$depresion = 20.88 + 0.61*tratamiento + \beta_{tiempo}*tiempo + \beta_{tratamiento:tiempo}*tratamiento:tiempo + b_{paciente} + \epsilon$

Donde: 

+ $\beta_{0}$ es el intercepto.
+ $\beta_{tratamiento}, \beta_{tiempo}, \beta_{tratamiento:tiempo}$ son los coeficientes asociados a las variables predictoras.
+ $b_{paciente}$ es el efecto aleatorio para cada paciente.

Esta ecuación representa la relación entre la variable de respuesta (depresión) y las variables predictoras (tratamiento, tiempo, y la interacción entre tratamiento y tiempo) considerando tanto los efectos fijos como los efectos aleatorios.

Podemos extraer y estudiar los efectos aleatorios de los pacientes 1 y 26.

```{r}
library(lme4)
efectos_aleatorios <- ranef(modelo1)$paciente

efecto_paciente1 <- efectos_aleatorios[1, ]
efecto_paciente26 <- efectos_aleatorios[26, ]

cat("Paciente 1:", efecto_paciente1)
cat("\n")
cat("Paciente 26:", efecto_paciente26)
```

Para el paciente 1: El valor positivo sugiere que su respuesta en depresión es aproximadamente 0.895 unidades más alta de lo esperado basándose en el modelo global. En otras palabras, el paciente 1 experimenta una depresión más elevada de lo que se predice por el modelo para el conjunto de datos en su totalidad.

Para el paciente 26: El valor positivo de 0.612 sugiere que su respuesta en depresión es aproximadamente 0.612 unidades más alta de lo esperado basándose en el modelo global. En este caso, el paciente 26 también experimenta una depresión más elevada de lo predicho por el modelo.

Estos valores proporcionan información sobre la variabilidad individual entre los pacientes en términos de la respuesta a la depresión. Es importante tener en cuenta que estos efectos aleatorios representan la diferencia entre la respuesta real de cada paciente y la respuesta predicha por los efectos fijos del modelo global.

En resumen, un valor positivo indica que el paciente tiene una respuesta más alta de lo esperado, mientras que un valor negativo indicaría una respuesta más baja de lo esperado.

En cuanto a los efectos fijos o coeficientes:

```{r}
summary(modelo1)
```

Como hemos explicado antes, tanto para el paciente 1 como para el 26, la depresión diminuye conforme el tiempo aumenta.