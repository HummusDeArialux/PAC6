---
title: "PAC6"
author: "Maria Lucas Gascón"
date: "2024-01-17"
output: word_document
---

# Problema 1

Cargamos los datos del problema.

```{r}
# Seteamos el directorio de trabajo
setwd("D:/Antiguos estudios/MASTER2/Sem3/Diseño/PAC6/PAC6")

# Importamos los datos
data <- read.csv("dades_problema1_pec6.csv", dec = ",", header = TRUE, sep = ";")

# Marcamos los factores
data$espectrometro <- as.factor(data$espectrometro)
data$suelo <- as.factor(data$suelo)
data$dia <- factor(data$dia, levels = c(1, 2, 3), labels = c("dia1", "dia2", "dia3"))
```

## 1.1 Análisis descriptivo de los datos

```{r}
# Primero examinamos la variable ratio
summary(data)

# Box plot de ratio por espectrometro
boxplot(ratio ~ espectrometro, data = data, col = c("blue4", "aquamarine2", "cadetblue1"), main = "Boxplot de Ratio por Espectrómetro")

# Box plot de ratio por suelo
boxplot(ratio ~ suelo, data = data, col = c("darkslateblue", "darkviolet"), main = "Boxplot de Ratio por Suelo")

# Box plot de ratio por dia
boxplot(ratio ~ dia, data = data, col = c("darkgreen", "chartreuse3", "darkolivegreen2"), main = "Boxplot de Ratio por Dia")
```

```{r, fig.width=15, fig.height=10}
# Create an interaction factor of espectrometro and suelo
espectrometro_suelo <- interaction(data$espectrometro, data$suelo)

# Box plot of ratio by espectrometro and suelo
boxplot(data$ratio ~ espectrometro_suelo, col = c("blue4", "aquamarine2", "cadetblue1", "darkslateblue", "darkviolet", "pink3"), 
        main = "Boxplot de Ratio por Espectrómetro y Suelo")
```

En el análisis del boxplot correspondiente al "Ratio por Espectrómetro", se observa una ligera disparidad en las mediciones entre los espectrómetros. Esta discrepancia se evidencia mediante la diferencia en la altura de las cajas y la variación en la media de las mediciones, destacada por una línea negra en cada caja.

En cuanto al boxplot relativo al "Ratio por Suelo", se destaca que el suelo rural presenta, en general, un ratio de 14N a 15N superior al observado en el suelo urbano. Esta diferencia se refleja tanto en la altura como en el ancho de las cajas, indicando que el suelo rural exhibe un ratio más elevado en comparación con el suelo urbano.

Adicionalmente, se observa una notable consistencia en las mediciones diarias, ya que muestran una variación mínima.

Al combinar los datos de espectrómetro y suelo en un único gráfico, se puede evaluar la interacción entre ambos factores. Se aprecia que, para el suelo urbano, las mediciones de los espectrómetros presentan una mayor disparidad en comparación con el suelo rural, donde las mediciones son más uniformes. Específicamente, se destaca que el espectrómetro 2 en el suelo urbano proporciona mediciones notablemente más bajas.

## 1.2 Modelo lineal

En este problema, se busca modelar la proporción de 14N a 15N en dos tipos de suelos (urbano, rural) utilizando tres espectrómetros distintos. Se realizaron mediciones en 18 muestras de cada tipo de suelo. Cada muestra se asignó a uno de los tres espectrómetros al azar, y para cada combinación de suelo y espectrómetro, se eligieron 3 días al azar para realizar las mediciones. El objetivo es analizar la influencia de los factores suelo, espectrómetro y día, así como sus interacciones.

El modelo lineal puede expresarse de la siguiente manera:

$Y_{ijk} = \mu + \alpha_{i} + \beta_{j} + (\alpha\beta)_{ij} + C_{k(ij)} + \epsilon_{ijk}$

+ $Y_{ijk}$ es la medida de la proporción de 14N a 15N para la k-ésima observación en el suelo i, espectrómetro j y día k.
+ $\mu$ es la media global.
+ $\alpha_{i}$ es el efecto del i-ésimo nivel del factor suelo. La suma de todos los efectos del factor suelo debe ser cero: $\sum_{i = 1}^{2} \alpha_{i}=0$
+ $\beta_{j}$ es el efecto del j-ésimo nivel del factor espectrómetro. La suma de todos los efectos del factor espectrómetro debe ser cero: $\sum_{j = 1}^{3} \beta_{i}=0$
+ $(\alpha\beta)_{ij}$ es la interacción entre el suelo i y el espectrómetro j. La suma de las interacciones debe ser cero: $\sum\alpha\beta_{ij}=0$
+ $C_{k(ij)}$ es el efecto del k-ésimo nivel del factor día anidado en la combinación suelo i y espectrómetro j. Como es un efecto aleatorio, no hay restricciones específicas, pero se asume que sigue una distribución normal con media cero: $C_{k(ij)} \sim N(0, \sigma^2_{C})$
+ $\epsilon_{ijk}$ es el error aleatorio asociado con la k-ésima observación en la combinación suelo i, espectrómetro j y día k. Se asume que sigue una distribución normal con media cero: $\epsilon_{ijk} \sim N(0, \sigma^2_{\epsilon})$

## 1.3 Hipótesis de interés

Para el factor suelo:

+ $H_{0} : \alpha_{1} = \alpha_{2} = 0$. No hay diferencia significativa en la proporción de 14N a 15N entre los suelos urbanos y rurales.
+ $H_{1}:$ Almenos un $\alpha_{i} \ne 0$. Hay al menos una diferencia significativa en la proporción de 14N a 15N entre los suelos urbanos y rurales.

Para el factor espectrómetro:

+ $H_{0}: \beta_{1} = \beta_{2} = \beta_{3} = 0$. No hay diferencia significativa en la proporción de 14N a 15N entre los espectrómetros.
+ $H_{1}:$ Almenos un $\beta_{j} \ne 0$. Hay al menos una diferencia significativa en la proporción de 14N a 15N entre los tres espectrómetros distintos.

Para la interacción suelo-espectrómetro:

+ $H_{0}: (\alpha\beta)_{ij} = 0$ para todos los $i, j$. No hay interacción significativa entre el tipo de suelo y el espectrómetro.
+ $H_{1}:$ Existe al menos una $(\alpha\beta)_{ij} \ne 0$. Hay al menos una interacción significativa entre el tipo de suelo y el espectrómetro.

Para el efecto aleatorio del día:

+ $H_{0}: \sigma^2_{C(AB)} = 0$. No hay variabilidad significativa asociada con los días anidados en la combinación de suelo y espectrómetro.
+ $H_{1}: \sigma^2_{C(AB)} > 0$. Existe variabilidad significativa asociada con los días anidados en la combinación de suelo y espectrómetro.

Para el error aleatorio:

+ $H_{0}: \sigma^2_{\epsilon} = 0$. No hay variabilidad significativa no explicada por los factores considerados en el modelo.
+ $H_{1}: \sigma^2_{\epsilon} > 0$. Existe variabilidad significativa no explicada por los factores considerados en el modelo.

## 1.4 Estudiar las hipótesis

```{r}
# Definimos el modelo
library(lme4)
library(car)

modelo <- lmer(ratio ~ suelo + espectrometro + suelo:espectrometro + (1 | dia:suelo:espectrometro), data = data)

summary(modelo)

# Intervalos de confianza
library(broom)
confint(modelo)
```

En la síntesis del modelo, no se evidencian los factores que resultan significativos. No obstante, es posible calcular los valores de confianza mediante el empleo de un valor crítico de la distribución t de Student. En esta distribución, un nivel de confianza del 0.05 implicaría un valor crítico de 1.96.

El intervalo de confianza se formula como el estimado del coeficiente más o menos 1.96 veces el error estándar del coeficiente. Para mayor conveniencia, este cálculo se realiza de forma automática mediante el paquete "broom".

Al examinar los intervalos de confianza, se constata que todos los factores son estadísticamente significativos, a excepción del espectrómetro 2, ya que su intervalo de confianza incluye el valor 0. Por otro lado, el intercepto, el suelo urbano, el espectrómetro 3 y las interacciones suelo urbano:espectrómetro 2 y suelo urbano:espectrómetro 3, exhiben diferencias significativas en comparación con la referencia establecida, que corresponde al suelo rural y el espectrómetro 1.

```{r}
# Testamos las hipótesis
anova_modelo <- Anova(modelo, type = "III", test = "Chisq")
print(anova_modelo)
```

La especificación de la ANOVA de "tipo III" implica la atribución de variabilidad a cada término, teniendo en cuenta todos los demás términos, incluidas las interacciones que involucran dicho término. Esta aproximación resulta útil cuando se presentan interacciones y se busca evaluar la contribución de cada variable a la variabilidad explicada, considerando las otras variables y sus interacciones.

Cabe destacar que, dado que no se han verificado las suposiciones de normalidad y homocedasticidad, se prefiere utilizar la prueba de Chi-cuadrado en lugar de la prueba F.

En cuanto a los resultados, se observa que tanto el suelo como la interacción suelo:espectrofotómetro son significativas (valor de p < 0.05), mientras que el espectrofotómetro por sí mismo no lo es (valor de p > 0.05). A continuación, se detalla la interpretación de estos hallazgos:

+ Suelo significativo: Se constatan diferencias estadísticamente significativas en la proporción de 14N a 15N entre los suelos urbanos y rurales (valor de p < 0.05, rechazo de H0), después de considerar los demás efectos en el modelo. En resumen, existe evidencia estadística que respalda la afirmación de que el tipo de suelo tiene un impacto significativo en la proporción de nitrógeno.

+ Espectrómetro no significativo: No se dispone de suficiente evidencia estadística para sostener que existen diferencias en la proporción de 14N a 15N entre los distintos espectrofotómetros (valor de p > 0.05, aceptación de H0), después de tomar en cuenta los otros efectos. En resumen, las variaciones observadas en la proporción de nitrógeno no pueden atribuirse de manera significativa a las diferencias entre los espectrofotómetros utilizados. Es posible que la no significancia se deba a que el espectrofotómetro 3 no difiere, a pesar de que el 2 sí lo hace según el intervalo de confianza.

+ Interacción suelo-espectrómetro significativa: Se evidencia que la influencia del espectrofotómetro en la proporción de nitrógeno depende del tipo de suelo (valor de p < 0.05, rechazo de H0). En otras palabras, la diferencia en la proporción de 14N a 15N entre los espectrofotómetros puede variar según si el suelo es urbano o rural. Esta interacción indica que el efecto del espectrofotómetro no es constante en todos los suelos y viceversa.

En resumen, los resultados sugieren que el tipo de suelo y la interacción entre el tipo de suelo y el espectrofotómetro son factores significativos en la variabilidad de la proporción de 14N a 15N, mientras que el espectrofotómetro por sí mismo no tiene un efecto significativo en esta proporción, aunque este patrón parece no aplicar al espectrofotómetro 2.

## 1.5 Comparaciones múltiples

Dado que el factor suelo consta únicamente de dos niveles, carece de fundamento llevar a cabo una comparación múltiple. A pesar de que el espectrómetro no muestra significancia de manera general, hemos observado que el espectrómetro 2 presenta un significado estadístico; procederemos a verificar estos resultados. Por último, examinaremos también la interacción suelo:espectrómetro.

#### Para la interacción:

```{r}
# install.packages("emmeans")
library(emmeans)
library(knitr)

# Realizamos las comparaciones múltiples
emmeans_result <- emmeans(modelo, pairwise ~ suelo:espectrometro)

# Ajustamos p-valores usando la corrección de Bonferroni
adjusted_emmeans <- summary(emmeans_result, infer = c(TRUE, TRUE), adjust = "bonferroni")

# Imprimimos los valores ajustados
print(adjusted_emmeans)
```

Como podemos ver, las siguientes combinaciones resultan significativas:

```{r}
# Extraemos los contrastes y p-valores
contrast_df <- as.data.frame(adjusted_emmeans$contrasts)

# Filtramos por p-valores < 0.05
significant_contrasts <- contrast_df[contrast_df$p.value < 0.05, c("contrast", "p.value")]


# Formateamos la tabla para imprimir
formatted_table <- data.frame(
  Contrast = significant_contrasts$contrast,
  P_Value = sprintf("%.4f", significant_contrasts$p.value)
)

# Imprimimos la tabla
library(knitr)
kable(formatted_table, col.names = c("Contraste", "P-Valor"), format = "pandoc")
```

Eso significa que:

+ Hay evidencia significativa para afirmar que la proporción de nitrógeno en el suelo rural es diferente cuando se utiliza el espectrómetro_1 en comparación con el suelo urbano cuando se utiliza el espectrómetro_2.
+ Hay evidencia significativa para afirmar que la proporción de nitrógeno en el suelo rural es diferente cuando se utiliza el espectrómetro_2 en comparación con el suelo urbano cuando también se utiliza el espectrómetro_2.
+ Hay evidencia significativa para afirmar que la proporción de nitrógeno en el suelo urbano es diferente cuando se utiliza el espectrómetro_2 en comparación con el suelo rural cuando se utiliza el espectrómetro_3.
+ Hay evidencia significativa para afirmar que la proporción de nitrógeno en el suelo urbano es diferente cuando se utiliza el espectrómetro_2 en comparación con el mismo suelo urbano cuando se utiliza el espectrómetro_3.

Estos valores de p bajos indican que, tras ajustar para múltiples comparaciones, las diferencias observadas en estas combinaciones específicas son estadísticamente significativas. Para las demás combinaciones, no se detectan diferencias significativas.

Es relevante subrayar la importancia de realizar correcciones para mitigar el error de tipo 1, especialmente dado el gran número de comparaciones efectuadas. En este caso, se ha implementado la corrección de Bonferroni.

#### Para el espectrómetro:

```{r}
# Instalar el paquete emmeans si aún no lo has hecho
# install.packages("emmeans")

# Cargar el paquete
library(emmeans)

# Calcular las medias marginales ajustadas (LSMeans)
lsmeans_modelo <- emmeans(modelo, ~espectrometro)

# Comparaciones múltiples entre niveles de espectrómetros
comparaciones <- pairs(lsmeans_modelo)

# Ver los resultados
summary(comparaciones)

```

Se ratifica la existencia de una disparidad significativa entre el espectrómetro 2 y el espectrómetro 1, dado que se obtiene un valor de 0.03, lo cual conduce al rechazo de la hipótesis nula (H0) que sostiene que no existen diferencias entre ambos. Por otro lado, se constata la ausencia de discrepancias entre el espectrómetro 1 y el espectrómetro 3, así como entre el espectrómetro 2 y el espectrómetro 3 (valor de p > 0.05). Este resultado ya se reflejaba en el resumen del modelo, aunque la comparación entre el espectrómetro 2 y el espectrómetro 3 no estaba detallada.

# Problema 2

Cargamos los datos del problema.

```{r}
# Seteamos el directorio de trabajo
setwd("D:/Antiguos estudios/MASTER2/Sem3/Diseño/PAC6/PAC6")

# Importamos los datos
data <- read.csv("dades_problema2_pec6.csv", dec = ",", header = TRUE, sep = ";")

# Marcamos los factores
data$dieta <- as.factor(data$dieta)
```

## 2.1 Análisis descriptivo de los datos

```{r}
# Realiza un resumen descriptivo
summary(data)

# Gráfico relación consumo-incremento
color_dieta = c("tomato1", "olivedrab3", "turquoise", "slateblue2")

# Boxplot incremento por dieta
boxplot(incremento ~ dieta, data = data, col = color_dieta)

# Boxplot consumo por dieta
boxplot(consumo ~ dieta, data = data, col = color_dieta)

library(ggplot2)

# Gráfico de dispersión Incremento vs Consumo sin dieta
ggplot(data, aes(x = consumo, y = incremento)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Añade la línea de tendencia general
  labs(title = "Relación entre Incremento y Consumo",
       x = "Consumo",
       y = "Incremento") +
  theme_minimal()

# Gráfico de dispersión Incremento vs Consumo por dieta
ggplot(data, aes(x = consumo, y = incremento, color = factor(dieta))) +
  scale_color_manual(values = color_dieta) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Añade la línea de tendencia + 
  labs(title = "Relación entre Incremento y Consumo por Dieta",
       x = "Consumo",
       y = "Incremento") +
  theme_minimal()
```

Se evidencia una distribución equilibrada con 5 animales por cada tipo de dieta, lo que configura un diseño balanceado.

El análisis del primer boxplot, que representa la relación entre el incremento de peso y la dieta, sugiere variaciones significativas entre los grupos. Esto se infiere al observar diferencias en las alturas de las cajas y la línea central, que representa la media de cada grupo. Además, las distintas alturas y longitudes de las líneas de dispersión indican variabilidades divergentes entre los grupos.

En contraste, al examinar el segundo boxplot que relaciona el consumo de calorías con la dieta, se puede inferir si existen disparidades en el consumo calórico entre los grupos. Efectivamente, se observan diferencias notables entre los grupos.

Por otro lado, el gráfico que ilustra la relación entre el aumento de peso y el consumo calórico revela una correlación positiva general. A mayor consumo de calorías, se evidencia un mayor incremento de peso, y viceversa.

Al analizar esta relación de manera específica para cada dieta, se mantiene la correlación positiva, pero se aprecian pendientes distintas para cada tipo de dieta. Destaca que la dieta 4 exhibe la correlación positiva más pronunciada.

En conjunto, estos hallazgos contribuyen a una comprensión más profunda de las relaciones entre las variables, lo que facilita el ajuste preciso de los modelos de regresión.

## 2.2 Modelo Lineal

### Ajustando según el consumo calórico

El modelo lineal, teniendo en cuenta el consumo calórico, puede especificarse como:

$y_{ij} = \mu + \alpha_{i} + \beta X_{ij} + \epsilon_{ij}$

Donde:

+ $y_{ij}$ es el aumento de peso del animal $j$ bajo la dieta $i$.
+ $\mu$ es el intercepto común para todas las dietas.
+ $\alpha_{i}$ es el intercepto específico para la dieta $i$.
+ $\beta$ es la pendiente de regresión, que representa el efecto del consumo calórico en el aumento de peso.
+ $Xij$ es el consumo calórico del animal $j$ bajo la dieta $i$.
+ $\epsilon_{ij}$ son errores experimentales aleatorios con distribución normal, media 0 y varianza $\sigma^2$. ($\epsilon_{ij} \sim N(0, \sigma^2)$).

Suposiciones adicionales:

+ $\sum_{i}^{a} \alpha_{i}=0$
+ El coeficiente de regresión $\beta$ es el mismo para todos los grupos de tratamiento (dietas).
+ Las dietas no influyen sobre el consumo calórico (covariante $X$)

El modelo covariante propone utilizar una línea de regresión para cada tratamiento. Esta línea representa cómo la variable de interés cambia en relación con la covariable. Todas las líneas son similares en términos de la dirección de cambio, es decir, comparten la misma "pendiente" ($β$). Esto significa que todos los tratamientos responden de manera similar a la covariable.

Sin embargo, hay diferencias entre los tratamientos, y estas diferencias se reflejan en los términos independientes o "ordenadas al origen" ($\mu + \alpha_{i}$). Cada tratamiento tiene su propia ordenada al origen ($\alpha_{i}$), que se suma a una ordenada al origen común ($\mu$). Esto significa que aunque las líneas son paralelas, pueden tener alturas diferentes en el eje vertical, indicando que cada tratamiento puede tener un nivel inicial diferente en la variable de interés.

En resumen, el modelo utiliza líneas de regresión paralelas para representar cómo los diferentes tratamientos responden a la covariable, con la flexibilidad de tener diferentes niveles iniciales debido a los términos $\alpha_{i}$.

### Sin ajustar por consumo calórico

El modelo lineal, sin tener en cuenta el consumo calórico, puede especificarse como:

$y_{ij} = \mu + \alpha_{i} + \epsilon_{ij}$

Donde:

+ $y_{ij}$ es el aumento de peso del animal $j$ bajo la dieta $i$.
+ $\mu$ es el efecto medio global.
+ $\alpha_{i}$ es el efecto adicional de la dieta $i$ en comparación con el promedio global.
+ $\epsilon_{ij}$ son errores experimentales aleatorios con distribución normal, media 0 y varianza $\sigma^2$. ($\epsilon_{ij} \sim N(0, \sigma^2)$).

En este caso, el modelo lineal es mucho más simple porque no se tiene en cuenta la covariable consumo. Es por ello que este modelo simple describe cómo las observaciones ($y_{ij}$) se componen del nivel medio común ($\mu$), la contribución única de cada tratamiento ($\alpha_{i}$), y la variabilidad no explicada ($\epsilon_{ij}$).

## 2.3 Efecto de la dieta

# Ajustando el consumo

```{r}
# Ajustar el modelo lineal
modelo_con <- lm(incremento ~ dieta + consumo, data = data)

summary(modelo_con)
```

En el caso de variables dummy que representan categorías (como las dietas), el término constante (o intercepto) es la estimación del valor medio de la variable de respuesta para la categoría de referencia. En este caso, la dieta 1 es la categoría de referencia. Entonces, el término constante representará la estimación del aumento de peso medio para la dieta 1. Las otras variables dummy (dieta 2, dieta 3 y dieta 4) indicarán cómo difieren las otras dietas en comparación con la dieta 1. En resumen, se puede considerar que la dieta 1 es equivalente al intercepto en este contexto específico.

Una vez explicado esto, podemos ver en el resumen del modelo que la estimación para la dieta 1 (intercepto) es de 15.74, y para la dieta 2 es de -14.94. Esto quiere decir que la dieta 1 hace que el peso incremente más que con la dieta 2. No debemos confundir que el estimado de la dieta 2 sea negativo con que disminuya el peso, si no que aumenta pero en menor medida que con la dieta 1, que es con la que se está comparando. Esto concuerda con la exploración inicial de los datos, en la que la dieta 1 mostraba mayor incremento de peso que la dieta 2.

### Sin ajustar el consumo

```{r}
# Ajustar el modelo lineal
modelo_sin <- lm(incremento ~ dieta, data = data)

# Resumen del modelo
summary(modelo_sin)
```

En este caso, el estimado para la dieta 1 es de 63, mientras que para la dieta 2 es de -15.8. Como mencionamos previamente, esto indica que la dieta 1 está asociada con un mayor aumento de peso en comparación con la dieta 2.

Al comparar el estimado de la dieta 1 ajustando el modelo con y sin la covariable, notamos una diferencia sustancial en la estimación (15.74 vs 63). Esta disparidad probablemente se debe a la omisión del efecto del consumo calórico en el modelo sin covariable.

Como hemos observado en la exploración de datos, existe una relación positiva entre la covariable (consumo) y la variable de respuesta. Al no incluir esta covariable en el modelo, parte de la variabilidad debida al consumo se atribuye erróneamente a la variable dieta. Esto se refleja en un estimado más alto para la dieta 1, que sirve como referencia.

Al incorporar el consumo como una covariable en el modelo, estamos intentando aislar el efecto específico de la dieta en el aumento de peso, controlando o ajustando por las diferencias en el consumo entre las dietas. Este enfoque proporciona una estimación más precisa del efecto de la dieta, eliminando el posible sesgo en la relación entre la covariable y la variable de respuesta.

En resumen, al incluir el consumo como covariable, se mejora la capacidad del modelo para discernir entre los efectos de la dieta y el consumo en el aumento de peso, lo que resulta en estimaciones más ajustadas y potencialmente más precisas.

En resumen, al incluir el consumo como covariable, se está mejorando la capacidad del modelo para discernir entre los efectos de la dieta y el consumo en el aumento de peso, y, por lo tanto, se obtienen estimaciones más ajustadas y potencialmente más precisas.

## 2.4 Diagnosis de suposiciones

#### Independencia de los residuos

```{r}
# Gráfico de residuos vs. orden de observaciones
plot(resid(modelo_con) ~ seq_along(resid(modelo_con)))

library(lmtest)
# Prueba de Durbin-Watson para autocorrelación de los residuos
dwtest(modelo_con)
```



#### Homocedasticidad

```{r}
plot(modelo_con, which=1)

# Prueba de Breusch-Pagan para homocedasticidad
library(lmtest)
bptest(modelo_con)
```

La dispersión de los residuos es constante a medida que cambian los valores ajustados. Vemos una dispersión uniforme de puntos alrededor de cero, indicando homocedasticidad.

Por otro lado, la prueba de Breusch-Pagan testa la H0 de homocedasticidad. Como obtenemos un pvalor alto (mayor que 0.05) sugiere que no hay suficiente evidencia para rechazar la hipótesis nula, indicando homocedasticidad.

#### Normalidad

```{r}
plot(modelo_con, which=2)

shapiro.test(modelo_con$residuals)
```

Tanto a partir del QQ-Plot (puntos alrededor de la diagonal), como el test de Shapiro-Wilks (p-valor > 0,05), concluimos que los residuos son normales.

## 2.5 Diferencias entre dietas

Para determinar entre qué dietas hay diferencias significativas, se deben realizar pruebas de comparaciones múltiples.

```{r}
# Instalar y cargar el paquete multcomp
# install.packages("multcomp")
library(multcomp)

# Realizar comparaciones múltiples con el método de Tukey
comp <- glht(modelo_con, linfct = mcp(dieta = "Tukey"))

# Resumen de las comparaciones con ajuste de pvalores
resumen_comp <- summary(comp)
pvalores_ajustados <- p.adjust(resumen_comp$test$pvalues, method = "bonferroni")
resumen_comp$test$pvalues_ajustados <- pvalores_ajustados

# Mostrar el resumen con pvalores ajustados
print(resumen_comp)
```
Se han realizado comparaciones múltiples por el método Tukey, y después de ajustar los pvalores por Bonferroni, vemos que existen diferencias significativas entre las dietas 4 y 1, las dietas 3 y 2 y por último las dietas 4 y 3.

# Problema 3

Cargamos los datos del problema.

```{r}
# Seteamos el directorio de trabajo
setwd("D:/Antiguos estudios/MASTER2/Sem3/Diseño/PAC6/PAC6")

# Importamos los datos
data <- read.csv("dades_problema3_pec6.csv", dec = ".", header = TRUE, sep = ",")

# Marcamos los factores
data$tratamiento <- as.factor(data$tratamiento)
data$paciente <- as.factor(data$paciente)
data$tiempo <- as.factor(data$tiempo)
```

## 3.1 Análisis descriptivo

```{r}
# Realiza un resumen descriptivo
summary(data)

color_tratamiento = c("tomato1", "olivedrab3")

# Boxplot depresión por dieta
boxplot(depresion ~ tratamiento, data = data, col = color_tratamiento)

# Boxplot depresión por tiempo
boxplot(depresion ~ tiempo, data = data)

library(ggplot2)

# Gráfico de dispersión depresión vs tiempo
ggplot(data, aes(x = tiempo, y = depresion)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Añade la línea de tendencia general
  labs(title = "Relación entre Depresión y Tiempo",
       x = "Tiempo",
       y = "Depresión") +
  theme_minimal()

# Gráfico de dispersión depresión vs tiempo con tratamiento
ggplot(data, aes(x = tiempo, y = depresion, color = factor(tratamiento))) +
  scale_color_manual(values = color_tratamiento) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Añade la línea de tendencia + 
  labs(title = "Relación entre Depresión y Tiempo",
       x = "Tiempo",
       y = "Depresión") +
  theme_minimal()
```

```{r, fig.width=10, fig.height=15}
ggplot(data, aes(x = tiempo, y = depresion)) + 
  geom_smooth(method = "lm", level = 0.95) +
  geom_point() + 
  facet_wrap(~ paciente, nrow = 10, ncol = 5) +
  theme(
  )

```

## 3.2 Modelo lineal

$Y_{ij} = \beta_{0} + \beta_{1}*tratamiento_{i} +  \beta_{2}*tiempo_{ij} + \beta_{3}*(tratamiento_{i}$ x $tiempo_{ij}) + u_{i0} + u_{il}*tiempo_{ij} + \epsilon_{ij}$

Donde:

+ $Y_{ij}$ es la medida de depresión para la i-ésima paciente en la j-ésima visita.
+ $tratamiento_{i}$ es la variable indicadora para el tratamiento (1 si es activo, 0 si es placebo). Es decir, la "i" en $tratamiento_{i}$ no indica el indice del tratamiento si no el número de paciente, el propio "$tratamiento_{i}$" es indicador de tratamiento.
+ $tiempo_{ij}$ es el tiempo de la j-ésima visita para la i-ésima paciente.
+ $\beta_{0}$ es la intercepción fija del modelo.
+ $\beta_{1}$ es el efecto fijo del tratamiento.
+ $\beta_{2}$ es el efecto fijo del tiempo.
+ $\beta_{3}$ representa la interacción entre el tratamiento y el tiempo.
+ $u_{i0}$ es el término aleatorio que modela las diferencias individuales en las intercepciones.
+ $u_{il}$ es el término aleatorio que modela las diferencias individuales en las pendientes respecto al tiempo.
+ $\epsilon_{ij}$ es el término de error.

Cabe destacar que i=50 porque hay 50 pacientes y j=7 porque se mide la depresión en 7 visitas.

Este modelo puede expresarse en notación matricial de la siguiente manera:

$Y = X\beta + Zu + \epsilon$

Dimensiones:

+ N=50×7=350N=50×7=350: Número total de observaciones.
+ k: Número de tratamientos.
+ p: Número de efectos fijos no relacionados con el tratamiento.
+ q: Número de efectos aleatorios.

Ahora, definimos las matrices y vectores según estas dimensiones:

+ $Y$: Vector de todas las medidas de depresión, de dimensión 350×1350×1.
+ $X$: Matriz de regresión de efectos fijos, de dimensión 350×(k+p)350×(k+p).
+ $β$: Vector de coeficientes de efectos fijos, de dimensión (k+p)×1(k+p)×1.
+ $Z$: Matriz de regresión de efectos aleatorios, de dimensión 350×q350×q.
+ $u$: Vector de efectos aleatorios, de dimensión q×1q×1.
+ $\epsilon$: Vector de errores, de dimensión 350×1350×1.

Particionado para cada elemento, quedaría como:

$Y = $

$$\begin{bmatrix}
Y_{1} \\
Y_{2} \\
. \\
. \\
. \\
Y_{350}\\
\end{bmatrix}$$

## 3.3 Implementación del modelo

### Intercepciones aleatorias

Para ajustar este modelo, especificamos que depresión es la variable respuesta y tratamiento y tiempo son variables independientes. Con el término "tratamiento * tiempo", también incluimos la interacción entre el tratamiento y el tiempo, ya que podría haber efectos diferenciados del tiempo según el tipo de tratamiento. Por otro lado, "(1|paciente)" especifica que estamos modelando una intercepto aleatorio para cada paciente. Esto tiene en cuenta la variabilidad entre los pacientes.

```{r}
# install.packages("lme4", dependencies=TRUE)
# install.packages("Matrix", dependencies=TRUE)
library(lme4)

# Define el modelo con intercepciones aleatorias
modelo1 <- lmer(depresion ~ tratamiento * tiempo + (1|paciente), data = data)

# Muestra un resumen del modelo
summary(modelo1)
```

### Intercepciones y pendientes aleatorias

Para ajustar este modelo, especificamos que depresión es la variable respuesta y tratamiento y tiempo son variables independientes. Con el término "tratamiento * tiempo", también incluimos la interacción entre el tratamiento y el tiempo, ya que podría haber efectos diferenciados del tiempo según el tipo de tratamiento. Por otro lado, "(tiempo | paciente)" especifica que estamos modelando una intercepción aleatoria y una pendiente aleatoria para cada paciente.

El término (tiempo | paciente) implica que cada paciente puede tener su propia intercepción (efecto inicial) y pendiente (efecto en el tiempo) en relación con la variable de respuesta.


remove.packages("Matrix")
remove.packages("lme4")
install.packages("lme4", type = "source")
library(lme4)



```{r}
library(lme4)

# Define el modelo con intercepciones y pendientes aleatorias
modelo2 <- lmer(depresion ~ tratamiento * tiempo + (tratamiento | paciente), data = data)

# TRATAMIENTO O TIEMPO HOLA??

# Muestra un resumen del modelo
summary(modelo2)
```

### Comparación de modelos

#### Criterios de información

```{r}
# AIC y BIC
modelo1_AIC <- AIC(modelo1)
modelo1_BIC <- BIC(modelo1)
modelo2_AIC <- AIC(modelo2)
modelo2_BIC <- BIC(modelo2)

# Creamos un df
resultados_df <- data.frame(
  Model = c("Modelo con intercepciones aleatorias", "Modelo con intercepciones y pendientes aleatorias"),
  AIC = c(modelo1_AIC, modelo2_AIC),
  BIC = c(modelo1_BIC, modelo2_BIC)
)

library(knitr)
kable(resultados_df, format = "pandoc")
```

El AIC (Criterio de Información de Akaike) y el BIC (Criterio de Información Bayesiano), son medidas que evalúan la bondad de ajuste de un modelo, teniendo en cuenta su complejidad. En general, modelos con valores más bajos de AIC y BIC son considerados preferibles.

El AIC penaliza la complejidad del modelo menos que el BIC. Cuanto menor sea el valor de AIC, mejor se considera el modelo en términos de ajuste y parsimonia.

El BIC penaliza la complejidad del modelo de manera más fuerte que el AIC. Similar al AIC, un valor más bajo de BIC indica un mejor equilibrio entre ajuste y complejidad.

Según esta información, parece ser que el modelo con intercepciones aleatorias describe bien el modelo sin necesidad de tanta complejidad.

#### Comparación de modelos anidados

```{r}
# Comparación de modelos usando likelihood ratio test
anova(modelo1, modelo2)
```

Según la prueba de razón de la verosimilitud, parece ser que no se muestran diferencias significativas entre los dos modelos (pvalor > 0.05). Siendo este el caso, es preferible escoger el modelo más sencillo, ya que explica igual de bien los datos que el modelo más complejo.

Un valor de p menor que un umbral (por ejemplo, 0.05) indicaría que el modelo más complejo es preferible.

Cabe destacar que aunque los valores de AIC y BIC que nos proporciona la función anova son ligeramente distintos a los calculados a mano por la manera de calcularlos. Pero nos indican el mismo resultado, que es que parece ser que el modelo simple es mejor que el modelo complejo.

#### Diagnóstico de residuos

```{r}
# Gráfico de residuos para el modelo1
plot(residuals(modelo1) ~ fitted(modelo1))

# Gráfico de residuos para el modelo1
plot(residuals(modelo2) ~ fitted(modelo2))
```

En ninguno de los dos modelos se observan patrones inadecuados de los residuos, así que en ese sentido ambos son correctos.Una vez más, puesto que los dos son correctos el más sencillo es preferible.

Con todo esto concluimos que el modelo con intercepciones aleatorias es el más adecuado, ya que su ajuste es bueno y es más sencillo que el modelo con intercepciones y pendientes aleatorias.

## 3.4 Factores significativos

```{r}
summary(modelo1)
```

Como podemos ver, en el resumen del modelo no se muestran qué factores resultan significativos, pero podemos calcular los valores de confianzas usando un valor critico de la distribución de la t student. En este caso una valor de confianza de 0.05, implicaría un valor crítico de 1.96. 

Intervalo de confianza = Estimado de coeficiente +- 1.96 * Error estándard del coeficiente.

Para más comodidad, lo calculamos automáticamente con el paquete broom.

```{r}
# install.packages("broom")
library(broom)

# Intervalos de confianza
confint(modelo1)
```

Los factores significativos son aquellos en los que el intervalo de confianza no incluye el valor 0. 

Podemos observar que sólo el intervalo de confianza del tratamiento1 incluye el valor 0. Es decir que el resto de factores (tiempo e interacción tiempo-tratamiento) son significativos, pero no el tratamiento.

Esto no es muy esperanzador para el estudio clínico, ya que parece ser que el tratamiento no tiene efecto sobre la depresión, si no que esta disminuye naturalmente a lo largo del tiempo en las pacientes independientemente del fármaco.

Sin embargo, al tener una interacción significativa parece ser que la relación entre el tratamiento y la respuesta de depresión cambia significativamente a lo largo del tiempo. En otras palabras, el efecto del tratamiento puede ser diferente en diferentes momentos del estudio. Esto podría estudiarse más detalladamente para esclarecerse mejor: Podría ser que el tratamiento no tenga un efecto inmediato, pero a medida que pasa el tiempo, se vuelva significativo. Esto podría sugerir que se necesita tiempo para que el tratamiento tenga un impacto en la respuesta de depresión. O bien que el tratamiento tenga un efecto significativo en algunos momentos específicos (por ejemplo, ciertos períodos de tiempo después de la administración), pero no en otros. O finalmente que el tratamiento afecte de manera diferente a la respuesta de depresión en distintos momentos del estudio, y estas variaciones a lo largo del tiempo se combinan de tal manera que el efecto general del tratamiento no es significativo.

Se podrían realizar más análisis post-hoc y análisis exploratorios para acabar de esclarecer estos efectos.

## 3.5 Modelo estimado en las pacientes 1 y 26

Tal y como hemos explicado antes:

$depresion = \beta_{0} + \beta_{tratamiento}*tratamiento + \beta_{tiempo}*tiempo + \beta_{tratamiento:tiempo}*tratamiento:tiempo + b_{paciente} + \epsilon$

$depresion = 20.88 + 0.61*tratamiento + \beta_{tiempo}*tiempo + \beta_{tratamiento:tiempo}*tratamiento:tiempo + b_{paciente} + \epsilon$

Donde: 

+ $\beta_{0}$ es el intercepto.
+ $\beta_{tratamiento}, \beta_{tiempo}, \beta_{tratamiento:tiempo}$ son los coeficientes asociados a las variables predictoras.
+ $b_{paciente}$ es el efecto aleatorio para cada paciente.

Esta ecuación representa la relación entre la variable de respuesta (depresión) y las variables predictoras (tratamiento, tiempo, y la interacción entre tratamiento y tiempo) considerando tanto los efectos fijos como los efectos aleatorios.

Podemos extraer y estudiar los efectos aleatorios de los pacientes 1 y 26.

```{r}
library(lme4)
efectos_aleatorios <- ranef(modelo1)$paciente

efecto_paciente1 <- efectos_aleatorios[1, ]
efecto_paciente26 <- efectos_aleatorios[26, ]

cat("Paciente 1:", efecto_paciente1)
cat("\n")
cat("Paciente 26:", efecto_paciente26)
```

Para el paciente 1: El valor positivo sugiere que su respuesta en depresión es aproximadamente 0.895 unidades más alta de lo esperado basándose en el modelo global. En otras palabras, el paciente 1 experimenta una depresión más elevada de lo que se predice por el modelo para el conjunto de datos en su totalidad.

Para el paciente 26: El valor positivo de 0.612 sugiere que su respuesta en depresión es aproximadamente 0.612 unidades más alta de lo esperado basándose en el modelo global. En este caso, el paciente 26 también experimenta una depresión más elevada de lo predicho por el modelo.

Estos valores proporcionan información sobre la variabilidad individual entre los pacientes en términos de la respuesta a la depresión. Es importante tener en cuenta que estos efectos aleatorios representan la diferencia entre la respuesta real de cada paciente y la respuesta predicha por los efectos fijos del modelo global.

En resumen, un valor positivo indica que el paciente tiene una respuesta más alta de lo esperado, mientras que un valor negativo indicaría una respuesta más baja de lo esperado.

En cuanto a los efectos fijos o coeficientes:

```{r}
summary(modelo1)
```

Como hemos explicado antes, tanto para el paciente 1 como para el 26, la depresión diminuye conforme el tiempo aumenta.